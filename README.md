# Open-Vocabulary-Segmentation

## Проект: Open-vocabulary сегментация и поиск объектов по текстовому запросу (zero-shot)

**Цель** — проверить, насколько хорошо предобученные foundation-модели умеют находить на изображении объекты заданного типа по текстовому описанию, без дообучения на датасете.
Для этого используются две готовые модели:

**SAM** (Segment Anything) — выдаёт набор масок объектов/областей на изображении

**CLIP** — переводит текст и изображение в эмбеддинги, чтобы сравнивать их по косинусному сходству

## Данные

Используется подмножество ScanNet++ (сцена 0a7cc12c0e):

images_0a7cc — RGB изображения

gt_semantic_2d — ground truth маски (для оценки качества)
